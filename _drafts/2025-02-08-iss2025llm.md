---
title: ISSessions CTF 2025 LMM Category Writeup
layout: post
--- 

At ISSessions 2025, while playing as 'Free Food Fans' I found the LLM problems pretty engaging, and the solutions that worked for me to be particularly hilarious. I even scored first blood on the final one!

# Pwetty Please?

The LLM UI is as shown:

![](/assets/images/iss2025llm/chatbotv1ui.png)

Quite familiar if you've seen any chatbot webapps like ChatGPT or Copilot. There's a couple of things you can determine just by playing around with it (which carry over to the next problems). 

1. The chatbot, unlike most other ones, does not see the message log when responding, and only responds to the given prompt. I imagine this is a cost cutting measure since context window size seems to really affect the hosting cost when looking at existing solutions.

![](/assets/images/iss2025llm/llm-memory.png)

2. The chatbot knows the flag. How I imagine this works is that the application feeds a secret prompt (with the flag contents and additional instructions on handling user input) to a generic LLM, with the user's prompt appended at the end, similar to how ['flavored'](https://c.ai) chatbots work.

![](/assets/images/iss2025llm/doyouknowtheflag.png)

Lets start probing it for the flag then.

### Strategy 1: Asking nicely

